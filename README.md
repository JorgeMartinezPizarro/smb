# Support Mail Bot (SMB) ğŸ“¬ğŸ¤–

SMB is a modular AI-powered system to automate email support using local LLMs, semantic search, and historical interaction context.

## ğŸ§  What it does

SMB receives incoming emails, vectorizes them, retrieves relevant past interactions from a local SQLite database, and generates a personalized response using a lightweight containerized LLM.

## ğŸ§± Architecture Overview

Mailer
A minimalist Python IMAP/SMTP client that fetches incoming emails and formats them for processing.

GPT
A local containerized inference server running a quantized model (e.g., Mistral 7B Q4) using llama.cpp or compatible backends.

Orchestrator
The system core: vectorizes messages, retrieves context, assembles the prompt, and calls the model to generate responses.

Database (SQLite)
Stores historical Q&A pairs, human-verified corrections (errata), and support annotations, to improve context over time.

## âš™ï¸ Requirements

Docker & Docker Compose

Python 3.10+

Compatible LLM model (already included in the image)

## ğŸš€ How to Run

```
git clone https://github.com/JorgeMartinezPizarro/smb
cd smb
make up
```

Configure email credentials and model parameters in the .env file before running.

## ğŸ§ª System Flow

An email is received from a user.

The message is vectorized and semantically compared against stored interactions.

Relevant context is embedded into a dynamic prompt.

A local LLM generates a natural language reply.

The reply is sent back via SMTP, and the interaction is stored for future context.

## ğŸ“¦ File Structure

```
smb/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Makefile
â”œâ”€â”€ README.md
â””â”€â”€ src
â”œâ”€â”€ db/
â”‚ â”œâ”€â”€ Dockerfile
â”‚ â”œâ”€â”€ entrypoint.sh
â”‚ â””â”€â”€ init.sql
â”œâ”€â”€ gpt/
â”‚ â”œâ”€â”€ Dockerfile
â”‚ â”œâ”€â”€ entrypoint.sh
â”‚ â”œâ”€â”€ load_model.py
â”‚ â””â”€â”€ requirements.txt
â”œâ”€â”€ mailer/
â”‚ â”œâ”€â”€ Dockerfile
â”‚ â””â”€â”€ main.py
â””â”€â”€ orchestrator/
â”œâ”€â”€ data/
â”‚ â””â”€â”€ faq.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ faq_ingest.py
â”œâ”€â”€ main.py
â”œâ”€â”€ prompt.txt
â””â”€â”€ retriever.py
```

## âœ¨ Features

Vector-based retrieval of historical support cases

Modular pipeline with shell-level orchestration

Custom prompt generation per message

Fully local LLM usage â€” no API keys or external services required

Flexible data ingestion (FAQs, human corrections, error reports)

## ğŸ“œ License: HAAT

This product is licensed as a "[haat]"(https://github.com/JorgeMartinezPizarro/haat/blob/main/LICENSE.md).


## ğŸ‘¤ Author

Jorge MartÃ­nez Pizarro

A mathematical programmer

https://ideniox.com