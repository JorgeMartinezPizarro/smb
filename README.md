# Support Mail Bot (SMB) ğŸ“¬ğŸ¤–

SMB is a modular AI-powered system to automate email support using local LLMs, semantic search, and historical interaction context.

## ğŸ§  What it does

SMB receives incoming emails, vectorizes them, retrieves relevant past interactions from a local SQLite database, and generates a personalized response using a lightweight containerized LLM.

## ğŸ§± Architecture Overview

Mailer
A mail client that scan new email and request an action to orquestrtor.

GPT
A dockerized llama model mistral 7b for text generation.

Orchestrator
The core, that create the prompt using vectorized content, historical and predefined rules. It receive an email and generate a valid response.

Database (SQLite)
Storage for metrics and other information that can be used to fix bugs and improve the system.

## âš™ï¸ Requirements

- Docker
- Make

## ğŸš€ How to Run

```
git clone https://github.com/JorgeMartinezPizarro/smb
cd smb
make up
```

Configure email credentials and model parameters in the .env file before running.

## ğŸ§ª System Flow

An email is received from a user.

Relevant context is embedded into a dynamic prompt.

A local LLM generates a natural language reply.

The reply is sent back via SMTP.

The interaction is stored for future context.

## ğŸ“¦ File Structure

```
smb/
â”œâ”€â”€ assets
â”‚Â Â  â”œâ”€â”€ faq.txt
â”‚Â Â  â””â”€â”€ prompt.txt
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Makefile
â”œâ”€â”€ README.md
â””â”€â”€ src
    â”œâ”€â”€ db
    â”‚Â Â  â”œâ”€â”€ Dockerfile
    â”‚Â Â  â”œâ”€â”€ entrypoint.sh
    â”‚Â Â  â””â”€â”€ init.sql
    â”œâ”€â”€ gpt
    â”‚Â Â  â”œâ”€â”€ Dockerfile
    â”‚Â Â  â”œâ”€â”€ entrypoint.sh
    â”‚Â Â  â”œâ”€â”€ load_model.py
    â”‚Â Â  â””â”€â”€ requirements.txt
    â”œâ”€â”€ mailer
    â”‚Â Â  â”œâ”€â”€ Dockerfile
    â”‚Â Â  â””â”€â”€ main.py
    â””â”€â”€ orchestrator
        â”œâ”€â”€ Dockerfile
        â”œâ”€â”€ faq_ingest.py
        â”œâ”€â”€ main.py
        â””â”€â”€ retriever.py
```

## âœ¨ Features

Modular pipeline with shell-level orchestration

Custom prompt generation per message

Fully local LLM usage â€” no API keys or external services required

Flexible data ingestion (FAQs, human corrections, error reports)

## ğŸ‘¤ Author

Jorge MartÃ­nez Pizarro

A mathematical programmer

https://ideniox.com

## ğŸ“œ License

This product is licensed as a [haat](https://github.com/JorgeMartinezPizarro/haat/blob/main/LICENSE.md).
