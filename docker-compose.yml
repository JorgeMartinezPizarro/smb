services:
  gpt-cpu:
    build:
      context: ./src/gpt
      args:
        USE_GPU: "false"
    profiles: ["cpu"]
    environment:
      - MODEL_PATH=/app/models/mistral-7b-instruct.Q4_K_M.gguf
      - USE_GPU=false
      - BATCH_SIZE=${BATCH_SIZE}
      - NUM_THREADS=${NUM_THREADS}
    volumes:
      - ./cache/models:/app/models
      - ./cache/cache:/root/.cache/llama_cpp
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 20s
      timeout: 10s
      retries: 10
      start_period: 60s

  gpt-gpu:
    build:
      context: ./src/gpt
      args:
        USE_GPU: "true"
    profiles: ["gpu"]
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - MODEL_PATH=/app/models/openhermes-2.5-mistral-7b.Q8_0.gguf
      - USE_GPU=true
      - BATCH_SIZE=${BATCH_SIZE}
      - NUM_THREADS=${NUM_THREADS}
    volumes:
      - ./cache/models:/app/models
      - ./cache/cache:/root/.cache/llama_cpp
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 20s
      timeout: 10s
      retries: 10
      start_period: 60s

  mailer:
    build: ./src/mailer
    depends_on:
      - ${GPT_SERVICE}
    environment:
      - EMAIL_USER=${MAIL_USER}
      - EMAIL_PASS=${MAIL_PASS}
      - IMAP_SERVER=${MAIL_HOST}
      - ORCHESTRATOR_URL=http://orchestrator:5000/process_email
  db:
    build: ./src/db
    volumes:
      - ./cache/sqlite:/data

  orchestrator:
    build: ./src/orchestrator
    depends_on:
      - ${GPT_SERVICE}
    environment:
      - DB_PATH=/data/db.sqlite
      - GPT_URL=http://${GPT_SERVICE}:5000/gpt
      - BOT_EMAIL=${MAIL_USER}
      - BOT_PASS=${MAIL_PASS}
      - SMTP_SERVER=${MAIL_HOST}
      - USE_GPU=false
    volumes:
      - ./cache/sqlite:/data
      - ./cache/vector_db:/app/vector_db
      - ./assets/:/app/assets
